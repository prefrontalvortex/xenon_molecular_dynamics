{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "## Michael McDermott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization was conducted to improve the performance of the LJ Molecular Dynamics program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on runtimes:\n",
    "#### I discovered about halfway through my work that the run time is dependent on step size. Most of the benchmarking is done at 1e-12 s step, but the computation is all done at 1e-13 or 1e-14. I am not sure why this is, as the \"virtual\" time should have no influence over the actual run time, but my guess is it has to do with the relative frequency that the force calculation exits early. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![iterspeed](./iterspeedpng.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bone-stock performance\n",
    "#### Program was run on an i3-3120M 2.5 Ghz (4 threads). A typical speed benchmark consists of running with time step = 1e-12 seconds and end time = 1e-10.  Initialization (populating the simulation with atoms) is timed separately from iterations. Initialization time is fixed with respect to simulation. Iters/second are computed from after simulation. \n",
    "Compiling: `gcc main.c aux.c -lm -o plain.run`\n",
    "\n",
    "    Number of iterations: 101\n",
    "    Initialization seconds: 2.751\n",
    "    Elapsed seconds: 22.519\n",
    "    Iterations per second: 4.49\n",
    "    \n",
    "    Number of iterations: 101\n",
    "    Initialization seconds: 2.684\n",
    "    Elapsed seconds: 30.022\n",
    "    Iterations per second: 3.36\n",
    "    \n",
    "    Number of iterations: 101\n",
    "    Initialization seconds: 2.106\n",
    "    Elapsed seconds: 21.016\n",
    "    Iterations per second: 4.81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline speed (iterations/sec): 4.22\n"
     ]
    }
   ],
   "source": [
    "baseline = np.mean([4.49, 3.36, 4.81])\n",
    "print(\"Baseline speed (iterations/sec): {:.2f}\".format(baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe to file\n",
    "#### This optimization seeks to eliminate some overhead by directly outputing to a file (bash > redirect) rather than standard out. This had no effect, however since future attempts would all be piping to a file, I wanted to control for this effect.\n",
    "\n",
    "    Initialization seconds: 2.688\n",
    "    Elapsed seconds: 29.506\n",
    "    Iterations per second: 3.42\n",
    "\n",
    "    Initialization seconds: 2.141\n",
    "    Elapsed seconds: 20.995\n",
    "    Iterations per second: 4.81\n",
    "\n",
    "    Initialization seconds: 2.080\n",
    "    Elapsed seconds: 21.157\n",
    "    Iterations per second: 4.77\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization flags\n",
    "### -O1 - 2.5x improvement\n",
    "\n",
    "\n",
    "    Elapsed seconds: 9.326\n",
    "    Iterations per second: 10.83\n",
    "\n",
    "    Elapsed seconds: 6.677\n",
    "    Iterations per second: 15.13\n",
    "    \n",
    "    Elapsed seconds: 7.022\n",
    "    Iterations per second: 14.38\n",
    "\n",
    "\n",
    "### -O2\n",
    "\n",
    "    Initialization seconds: 2.049\n",
    "    Elapsed seconds: 8.594\n",
    "    Iterations per second: 11.75\n",
    "\n",
    "    Initialization seconds: 1.991\n",
    "    Elapsed seconds: 8.921\n",
    "    Iterations per second: 11.32\n",
    "\n",
    "    Initialization seconds: 1.627\n",
    "    Elapsed seconds: 6.439\n",
    "    Iterations per second: 15.68\n",
    "    \n",
    "### -O3\n",
    "\n",
    "    Initialization seconds: 2.072\n",
    "    Elapsed seconds: 8.269\n",
    "    Iterations per second: 12.21\n",
    "\n",
    "    Initialization seconds: 1.604\n",
    "    Elapsed seconds: 6.123\n",
    "    Iterations per second: 16.50\n",
    "\n",
    "    Initialization seconds: 1.618\n",
    "    Elapsed seconds: 6.085\n",
    "    Iterations per second: 16.60\n",
    "\n",
    "#### Because O3 optimization provides a great effect with no cost to accuracy, it'll be used from here on out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O3 flag (it/sec): 15.10\n",
      "Gain: 3.58x\n"
     ]
    }
   ],
   "source": [
    "o3flag = np.mean([12.21, 16.5, 16.6])\n",
    "print(\"O3 flag (it/sec): {:.2f}\\nGain: {:.2f}x\".format(o3flag, o3flag/baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bogothreading\n",
    "#### True hyperthreading with a simulation such as this is very challenging, since the entire system is interconnected. However, what can be done is run the experiment several times in parallel in order to improve the resolution. 8 simultaneous experiments were run on an i7-6700 8-thread processor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "#### With a fair bit of tweaking, I was able to split the most intensive part of the code, the force calculation (an O(nÂ²) algorithm), by sending 1/n of the calculations to n threads (in my case 4 was ideal). Spawning a thread incurs a small overhead, on the order of 10 ms. However, given than an average loop is about  60 ms, by using 4 threads, I can theoretically get up to 40 iterations/second (15+10 ms each). Actual gain is 37.7 it/sec, or a ninefold speedup of the original code (2.5x O3 single threaded). \n",
    "\n",
    "    Elapsed seconds: 2.661\n",
    "    Iterations per second: 37.96\n",
    "\n",
    "    Elapsed seconds: 2.702\n",
    "    Iterations per second: 37.39\n",
    "\n",
    "    Elapsed seconds: 2.672\n",
    "    Iterations per second: 37.79\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 threads (it/sec): 37.71\n",
      "Gain: 8.94x\n",
      "Gain w.r.t O3 single thread: 2.50x\n"
     ]
    }
   ],
   "source": [
    "thread4 = np.mean([37.96, 37.39, 37.79])\n",
    "print(\"4 threads (it/sec): {:.2f}\\nGain: {:.2f}x\".format(thread4, thread4/baseline))\n",
    "print(\"Gain w.r.t O3 single thread: {:.2f}x\".format(thread4/o3flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
